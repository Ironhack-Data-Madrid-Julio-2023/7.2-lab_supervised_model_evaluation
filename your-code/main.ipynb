{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.model_selection import train_test_split as tts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.1.3 in /Users/margahedo/anaconda3/lib/python3.10/site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/margahedo/anaconda3/lib/python3.10/site-packages (from scikit-learn==1.1.3) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/margahedo/anaconda3/lib/python3.10/site-packages (from scikit-learn==1.1.3) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/margahedo/anaconda3/lib/python3.10/site-packages (from scikit-learn==1.1.3) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/margahedo/anaconda3/lib/python3.10/site-packages (from scikit-learn==1.1.3) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn==1.1.3\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston  # Dentro del módulo de sklearn importa un dataset con info de viviendas en Boston\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "'''Con este conjunto de datos, tengo características y una variable objetivo para predecir. \n",
    "Voy a crear X que contendrá un df con las características'''\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "\n",
    "'''También creo Y, que contiene la variable a predecir en numérico, MEDV significa que representa \n",
    "el valor mediano'''\n",
    "\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "'''Con concat los uno(concateno)'''\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404, 1), (102, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ahora voy a dividir los datos en conjuntos: utilizando train_test_split (tts). \n",
    "con test_size estoy creando un parámetro para tener un 20% para prueba y un 80% para entrenamiento.'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "\n",
    "'''Utilizo el modelo de regresión lineal con mis datos de entrenamiento. Son los datos que va a aprender para\n",
    "hacer las predicciones'''\n",
    "\n",
    "lreg = LinReg()\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "lreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-5.82218439],\n",
       "        [19.99985537],\n",
       "        [13.16536694],\n",
       "        [13.56857433],\n",
       "        [36.89551116]]),\n",
       " array([[20.83073963],\n",
       "        [ 6.12440968],\n",
       "        [26.98145013],\n",
       "        [29.39767286],\n",
       "        [24.59930613]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Aquí muestro las 5 primeras predicciones de la prueba y el entrenamiento'''\n",
    "\n",
    "yp_test = lreg.predict(X_test)\n",
    "yp_train = lreg.predict(X_train)\n",
    "\n",
    "yp_test[:5], yp_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7013983117335175, 0.7429286097554365)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "'''La R2 del entrenamiento y del test'''\n",
    "\n",
    "r2test = r2(y_test, yp_test)\n",
    "r2train = r2(y_train, yp_train)\n",
    "\n",
    "r2test, r2train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.190650475046425, 22.100710233135246)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse \n",
    "\n",
    "mse_test = mse(y_test, yp_test)\n",
    "mse_train = mse(y_train, yp_train)\n",
    "\n",
    "mse_test, mse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.276070661739392, 3.3377563409407127)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "mae_test = mae(y_test, yp_test)\n",
    "mae_train = mae(y_train, yp_train)\n",
    "\n",
    "mae_test, mae_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "''''''\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120, 1), (30, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ahora voy a dividir los datos en conjuntos: utilizando train_test_split (tts). \n",
    "con test_size estoy creando un parámetro para tener un 20% para prueba y un 80% para entrenamiento.'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Separo los datos en características y variable objetivo\n",
    "\n",
    "X = data.drop(\"class\", axis=1)\n",
    "y = data[\"class\"]\n",
    "\n",
    "# Divido los datos en entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Creo una instancia del modelo de Regresión Logística\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Entreno el modelo utilizando los datos de entrenamiento\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones de la prueba\n",
    "\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(train_accuracy)\n",
    "\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Balanceada en Entrenamiento: 0.9653972153972153\n",
      "Precisión Balanceada en Prueba: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calcular e imprimir la puntuación de precisión balanceada en el conjunto de entrenamiento\n",
    "train_balanced_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(\"Precisión Balanceada en Entrenamiento:\", train_balanced_accuracy)\n",
    "\n",
    "# Calcular e imprimir la puntuación de precisión balanceada en el conjunto de prueba\n",
    "test_balanced_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(\"Precisión Balanceada en Prueba:\", test_balanced_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en entrenamiento: 0.9672774327122153\n",
      "Precisión en prueba: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calcular e imprimir la puntuación de precisión para el conjunto de entrenamiento\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "print(\"Precisión en entrenamiento:\", train_precision)\n",
    "\n",
    "# Calcular e imprimir la puntuación de precisión para el conjunto de prueba\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "print(\"Precisión en prueba:\", test_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall en entrenamiento: 0.9666666666666667\n",
      "Recall en prueba: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calcular e imprimir el recall en el conjunto de entrenamiento\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "print(\"Recall en entrenamiento:\", train_recall)\n",
    "\n",
    "# Calcular e imprimir el recall en el conjunto de prueba\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "print(\"Recall en prueba:\", test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 en entrenamiento: 0.9665740740740743\n",
      "Puntaje F1 en prueba: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''Es la media armónica entre la precisión y el recall, \n",
    "proporciona una medida equilibrada del rendimiento del clasificador que tiene en cuenta tanto los falsos \n",
    "positivos como los falsos negativos'''\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calcular e imprimir el puntaje F1 para el conjunto de entrenamiento\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "print(\"Puntaje F1 en entrenamiento:\", train_f1)\n",
    "\n",
    "# Calcular e imprimir el puntaje F1 para el conjunto de prueba\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "print(\"Puntaje F1 en prueba:\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''La matriz de confusión muestra la cantidad de ejemplos clasificados correctos e incorrectos para cada clase'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión en entrenamiento:\n",
      "[[39  0  0]\n",
      " [ 0 34  3]\n",
      " [ 0  1 43]]\n",
      "Matriz de confusión en prueba:\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generar la matriz de confusión para el conjunto de entrenamiento\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Matriz de confusión en entrenamiento:\")\n",
    "print(train_cm)\n",
    "\n",
    "# Generar la matriz de confusión para el conjunto de prueba\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Matriz de confusión en prueba:\")\n",
    "print(test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m logreg_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, logreg_test_pred)\n\u001b[1;32m     16\u001b[0m logreg_precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, logreg_test_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m logreg_recall \u001b[38;5;241m=\u001b[39m \u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogreg_test_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m logreg_f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, logreg_test_pred)\n\u001b[1;32m     19\u001b[0m logreg_cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, logreg_test_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1920\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[1;32m   1790\u001b[0m     y_true,\n\u001b[1;32m   1791\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1797\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m ):\n\u001b[1;32m   1799\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1800\u001b[0m \n\u001b[1;32m   1801\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1920\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1563\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1381\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1380\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1384\u001b[0m         )\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1386\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Entrenar y evaluar diferentes modelos en el conjunto de entrenamiento y prueba\n",
    "\n",
    "# Modelo de Regresión Logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_train_pred = logreg.predict(X_train)\n",
    "logreg_test_pred = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_test_pred)\n",
    "logreg_precision = precision_score(y_test, logreg_test_pred, average='macro')\n",
    "logreg_recall = recall_score(y_test, logreg_test_pred)\n",
    "logreg_f1 = f1_score(y_test, logreg_test_pred)\n",
    "logreg_cm = confusion_matrix(y_test, logreg_test_pred)\n",
    "\n",
    "# Modelo de Árbol de Decisión\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_train_pred = decision_tree.predict(X_train)\n",
    "decision_tree_test_pred = decision_tree.predict(X_test)\n",
    "decision_tree_accuracy = accuracy_score(y_test, decision_tree_test_pred)\n",
    "decision_tree_precision = precision_score(y_test, decision_tree_test_pred)\n",
    "decision_tree_recall = recall_score(y_test, decision_tree_test_pred)\n",
    "decision_tree_f1 = f1_score(y_test, decision_tree_test_pred)\n",
    "decision_tree_cm = confusion_matrix(y_test, decision_tree_test_pred)\n",
    "\n",
    "# Modelo de Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_train_pred = random_forest.predict(X_train)\n",
    "random_forest_test_pred = random_forest.predict(X_test)\n",
    "random_forest_accuracy = accuracy_score(y_test, random_forest_test_pred)\n",
    "random_forest_precision = precision_score(y_test, random_forest_test_pred)\n",
    "random_forest_recall = recall_score(y_test, random_forest_test_pred)\n",
    "random_forest_f1 = f1_score(y_test, random_forest_test_pred)\n",
    "random_forest_cm = confusion_matrix(y_test, random_forest_test_pred)\n",
    "\n",
    "# Modelo de Naive Bayes\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "naive_bayes_train_pred = naive_bayes.predict(X_train)\n",
    "naive_bayes_test_pred = naive_bayes.predict(X_test)\n",
    "naive_bayes_accuracy = accuracy_score(y_test, naive_bayes_test_pred)\n",
    "naive_bayes_precision = precision_score(y_test, naive_bayes_test_pred)\n",
    "naive_bayes_recall = recall_score(y_test, naive_bayes_test_pred)\n",
    "naive_bayes_f1 = f1_score(y_test, naive_bayes_test_pred)\n",
    "naive_bayes_cm = confusion_matrix(y_test, naive_bayes_test_pred)\n",
    "\n",
    "# Modelo de SVM\n",
    "support_vector_machine = svm.SVC()\n",
    "support_vector_machine.fit(X_train, y_train)\n",
    "svm_train_pred = support_vector_machine.predict(X_train)\n",
    "svm_test_pred = support_vector_machine.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_test_pred)\n",
    "svm_precision = precision_score(y_test, svm_test_pred)\n",
    "svm_recall = recall_score(y_test, svm_test_pred)\n",
    "svm_f1 = f1_score(y_test, svm_test_pred)\n",
    "svm_cm = confusion_matrix(y_test, svm_test_pred)\n",
    "\n",
    "# Imprimir las métricas de evaluación para cada modelo\n",
    "print(\"Modelo de Regresión Logística:\")\n",
    "print(\"Accuracy:\", logreg_accuracy)\n",
    "print(\"Precision:\", logreg_precision)\n",
    "print(\"Recall:\", logreg_recall)\n",
    "print(\"F1-score:\", logreg_f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(logreg_cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
